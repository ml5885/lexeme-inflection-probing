{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5747eb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BASIC DATASET STATISTICS ===\n",
      "Total data points: 54816\n",
      "Unique sentences: 8415\n",
      "Unique lemmas: 7848\n",
      "Unique word forms: 11720\n",
      "Average tokens per sentence: 6.5\n",
      "\n",
      "Dataset Statistics Table:\n",
      "                     Statistic    Value\n",
      "0            Total data points  54816.0\n",
      "1             Unique sentences   8415.0\n",
      "2                Unique lemmas   7848.0\n",
      "3            Unique word forms  11720.0\n",
      "4  Average tokens per sentence      6.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from transformers import AutoTokenizer\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Model configurations\n",
    "MODEL_CONFIGS = {\n",
    "    \"gpt2\": {\n",
    "        \"model_name\": \"gpt2\",\n",
    "        \"tokenizer_name\": \"gpt2\",\n",
    "    },\n",
    "    \"pythia1.4b\": {\n",
    "        \"model_name\": \"EleutherAI/pythia-1.4b\",\n",
    "        \"tokenizer_name\": \"EleutherAI/pythia-1.4b\",\n",
    "    },\n",
    "    \"gemma2b\": {\n",
    "        \"model_name\": \"google/gemma-2-2b\",\n",
    "        \"tokenizer_name\": \"google/gemma-2-2b\",\n",
    "    },\n",
    "    \"qwen2\": {\n",
    "        \"model_name\": \"Qwen/Qwen2.5-1.5B\",\n",
    "        \"tokenizer_name\": \"Qwen/Qwen2.5-1.5B\",\n",
    "    },\n",
    "    \"bert-base-uncased\": {\n",
    "        \"model_name\": \"bert-base-uncased\",\n",
    "        \"tokenizer_name\": \"bert-base-uncased\",\n",
    "    },\n",
    "    \"bert-large-uncased\": {\n",
    "        \"model_name\": \"bert-large-uncased\",\n",
    "        \"tokenizer_name\": \"bert-large-uncased\",\n",
    "    },\n",
    "    \"deberta-v3-large\": {\n",
    "        \"model_name\": \"microsoft/deberta-v3-large\",\n",
    "        \"tokenizer_name\": \"microsoft/deberta-v3-large\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# Create figures directory if it doesn't exist\n",
    "os.makedirs('figures/', exist_ok=True)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"../data/ud_gum_dataset.csv\")\n",
    "\n",
    "# Basic dataset statistics\n",
    "print(\"=== BASIC DATASET STATISTICS ===\")\n",
    "total_points = len(df)\n",
    "unique_sentences = df['Sentence'].nunique()\n",
    "unique_lemmas = df['Lemma'].nunique()\n",
    "unique_forms = df['Word Form'].nunique()\n",
    "avg_tokens_per_sentence = df.groupby('Sentence').size().mean().round(1)\n",
    "\n",
    "print(f\"Total data points: {total_points}\")\n",
    "print(f\"Unique sentences: {unique_sentences}\")\n",
    "print(f\"Unique lemmas: {unique_lemmas}\")\n",
    "print(f\"Unique word forms: {unique_forms}\")\n",
    "print(f\"Average tokens per sentence: {avg_tokens_per_sentence}\")\n",
    "\n",
    "# Create a more detailed table for the paper\n",
    "dataset_stats = pd.DataFrame({\n",
    "    \"Statistic\": [\n",
    "        \"Total data points\", \n",
    "        \"Unique sentences\", \n",
    "        \"Unique lemmas\", \n",
    "        \"Unique word forms\",\n",
    "        \"Average tokens per sentence\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        total_points,\n",
    "        unique_sentences,\n",
    "        unique_lemmas,\n",
    "        unique_forms,\n",
    "        avg_tokens_per_sentence\n",
    "    ]\n",
    "})\n",
    "print(\"\\nDataset Statistics Table:\")\n",
    "print(dataset_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a10bc46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CATEGORY AND INFLECTION DISTRIBUTION ANALYSIS ===\n",
      "\n",
      "Distribution by Category:\n",
      "Category\n",
      "Noun         27111\n",
      "Verb         17093\n",
      "Adjective    10612\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Category Percentages:\n",
      "Category\n",
      "Noun         49.5\n",
      "Verb         31.2\n",
      "Adjective    19.4\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Distribution by Inflection Label:\n",
      "Inflection Label\n",
      "singular       19830\n",
      "base           10076\n",
      "positive        9926\n",
      "plural          7281\n",
      "past            5604\n",
      "3rd_pers        1413\n",
      "comparative      403\n",
      "superlative      283\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Inflection Label Percentages:\n",
      "Inflection Label\n",
      "singular       36.2\n",
      "base           18.4\n",
      "positive       18.1\n",
      "plural         13.3\n",
      "past           10.2\n",
      "3rd_pers        2.6\n",
      "comparative     0.7\n",
      "superlative     0.5\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Category-Inflection Combinations:\n",
      "Inflection Label  3rd_pers   base  comparative  past  plural  positive  \\\n",
      "Category                                                                 \n",
      "Adjective                0      0          403     0       0      9926   \n",
      "Noun                     0      0            0     0    7281         0   \n",
      "Verb                  1413  10076            0  5604       0         0   \n",
      "\n",
      "Inflection Label  singular  superlative  \n",
      "Category                                 \n",
      "Adjective                0          283  \n",
      "Noun                 19830            0  \n",
      "Verb                     0            0  \n",
      "\n",
      "Data split sizes:\n",
      "Train: 43852 examples (80.0%)\n",
      "Dev: 5482 examples (10.0%)\n",
      "Test: 5482 examples (10.0%)\n",
      "\n",
      "Inflection label distribution across splits:\n",
      "                     Train       Dev      Test\n",
      "Inflection Label                              \n",
      "singular          0.361762  0.361729  0.361729\n",
      "base              0.183823  0.183874  0.183692\n",
      "positive          0.181086  0.180956  0.181138\n",
      "plural            0.132833  0.132798  0.132798\n",
      "past              0.102230  0.102152  0.102335\n",
      "3rd_pers          0.025768  0.025903  0.025721\n",
      "comparative       0.007343  0.007297  0.007479\n",
      "superlative       0.005154  0.005290  0.005108\n"
     ]
    }
   ],
   "source": [
    "# increase matplotlib font size\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "# Distribution analysis and visualizations\n",
    "print(\"\\n=== CATEGORY AND INFLECTION DISTRIBUTION ANALYSIS ===\")\n",
    "\n",
    "# Distribution by category\n",
    "category_counts = df['Category'].value_counts()\n",
    "print(\"\\nDistribution by Category:\")\n",
    "print(category_counts)\n",
    "category_percentages = (100 * category_counts / len(df)).round(1)\n",
    "print(\"\\nCategory Percentages:\")\n",
    "print(category_percentages)\n",
    "\n",
    "# Distribution by inflection label\n",
    "inflection_counts = df['Inflection Label'].value_counts()\n",
    "print(\"\\nDistribution by Inflection Label:\")\n",
    "print(inflection_counts)\n",
    "inflection_percentages = (100 * inflection_counts / len(df)).round(1)\n",
    "print(\"\\nInflection Label Percentages:\")\n",
    "print(inflection_percentages)\n",
    "\n",
    "# Plot distribution of categories\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=category_counts.index, y=category_counts.values)\n",
    "plt.title('Distribution of Word Categories')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures//category_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot distribution of inflection labels\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.barplot(x=inflection_counts.index, y=inflection_counts.values)\n",
    "plt.title('Distribution of Inflection Labels')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures//inflection_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# Check category-inflection combinations\n",
    "category_inflection = df.groupby(['Category', 'Inflection Label']).size().unstack(fill_value=0)\n",
    "print(\"\\nCategory-Inflection Combinations:\")\n",
    "print(category_inflection)\n",
    "\n",
    "# Create data splits statistics\n",
    "# Create stratified splits by inflection label\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df['Inflection Label'], random_state=42)\n",
    "dev_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['Inflection Label'], random_state=42)\n",
    "\n",
    "print(\"\\nData split sizes:\")\n",
    "print(f\"Train: {len(train_df)} examples ({len(train_df)/len(df):.1%})\")\n",
    "print(f\"Dev: {len(dev_df)} examples ({len(dev_df)/len(df):.1%})\")\n",
    "print(f\"Test: {len(test_df)} examples ({len(test_df)/len(df):.1%})\")\n",
    "\n",
    "# Check if stratification worked correctly\n",
    "train_dist = train_df['Inflection Label'].value_counts(normalize=True)\n",
    "dev_dist = dev_df['Inflection Label'].value_counts(normalize=True)\n",
    "test_dist = test_df['Inflection Label'].value_counts(normalize=True)\n",
    "\n",
    "# Combine into a dataframe for easy comparison\n",
    "split_comparison = pd.DataFrame({\n",
    "    'Train': train_dist,\n",
    "    'Dev': dev_dist,\n",
    "    'Test': test_dist\n",
    "})\n",
    "print(\"\\nInflection label distribution across splits:\")\n",
    "print(split_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a98d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TOKENIZATION ANALYSIS ACROSS MODELS ===\n",
      "Loading gpt2 tokenizer...\n",
      "Loading pythia1.4b tokenizer...\n",
      "Loading gemma2b tokenizer...\n",
      "Loading qwen2 tokenizer...\n",
      "Loading bert-base-uncased tokenizer...\n",
      "Loading bert-large-uncased tokenizer...\n",
      "Loading deberta-v3-large tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelli/Desktop/11424/lexeme-inflection-probing/venv/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenization Statistics Across Models:\n",
      "                    avg_tokens_per_word  median_tokens_per_word  \\\n",
      "gpt2                             0.0945                     0.0   \n",
      "pythia1.4b                       0.0875                     0.0   \n",
      "gemma2b                          0.1880                     0.0   \n",
      "qwen2                            0.0670                     0.0   \n",
      "bert-base-uncased                1.1060                     1.0   \n",
      "bert-large-uncased               1.1060                     1.0   \n",
      "deberta-v3-large                 1.0260                     1.0   \n",
      "\n",
      "                    max_tokens_per_word  percent_multitoken  \n",
      "gpt2                                3.0                0.90  \n",
      "pythia1.4b                          3.0                0.90  \n",
      "gemma2b                             3.0                1.90  \n",
      "qwen2                               2.0                0.65  \n",
      "bert-base-uncased                   6.0                6.95  \n",
      "bert-large-uncased                  6.0                6.95  \n",
      "deberta-v3-large                    4.0                2.20  \n"
     ]
    }
   ],
   "source": [
    "# Tokenization analysis across all models\n",
    "print(\"\\n=== TOKENIZATION ANALYSIS ACROSS MODELS ===\")\n",
    "\n",
    "# Function to count tokens for a word\n",
    "def count_tokens(tokenizer, word):\n",
    "    try:\n",
    "        return len(tokenizer.encode(word))\n",
    "    except:\n",
    "        return float('nan')  # In case of errors\n",
    "\n",
    "# Create a sample of words to analyze (limit for speed)\n",
    "sample_size = min(2000, len(df))\n",
    "word_sample = df['Word Form'].sample(sample_size, random_state=42)\n",
    "\n",
    "tokenizer_stats = {}\n",
    "for model_name, config in MODEL_CONFIGS.items():\n",
    "    print(f\"Loading {model_name} tokenizer...\")\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(config['tokenizer_name'])\n",
    "        \n",
    "        # Count tokens for each word\n",
    "        token_counts = [count_tokens(tokenizer, word) for word in word_sample]\n",
    "        token_counts = [c for c in token_counts if not np.isnan(c)]  # Remove nan values\n",
    "        \n",
    "        # Compute statistics\n",
    "        tokenizer_stats[model_name] = {\n",
    "            \"avg_tokens_per_word\": np.mean(token_counts),\n",
    "            \"median_tokens_per_word\": np.median(token_counts),\n",
    "            \"max_tokens_per_word\": max(token_counts),\n",
    "            \"percent_multitoken\": 100 * sum(count > 1 for count in token_counts) / len(token_counts)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {model_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Display tokenization statistics\n",
    "tokenizer_df = pd.DataFrame(tokenizer_stats).T\n",
    "print(\"\\nTokenization Statistics Across Models:\")\n",
    "print(tokenizer_df)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "tokenizer_df['percent_multitoken'].plot(kind='bar')\n",
    "plt.title('Percentage of Words Split into Multiple Tokens')\n",
    "plt.ylabel('Percentage')\n",
    "plt.xlabel('Model')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures//multitoken_percentages.png')\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "tokenizer_df['avg_tokens_per_word'].plot(kind='bar')\n",
    "plt.title('Average Tokens per Word')\n",
    "plt.ylabel('Average Tokens')\n",
    "plt.xlabel('Model')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures//avg_tokens_per_word.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf945400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SENTENCE CONTEXT AND MORPHOLOGICAL RICHNESS ANALYSIS ===\n",
      "\n",
      "Average number of word forms per lemma: 1.53\n",
      "Median number of word forms per lemma: 1.0\n",
      "Maximum number of word forms per lemma: 16\n",
      "\n",
      "Top 10 lemmas by number of different word forms:\n",
      "Lemma\n",
      "be       16\n",
      "get      11\n",
      "go       10\n",
      "do        9\n",
      "light     9\n",
      "make      9\n",
      "take      8\n",
      "open      8\n",
      "try       8\n",
      "see       7\n",
      "Name: Word Form, dtype: int64\n",
      "\n",
      "Examples of rich inflection paradigms:\n",
      "\n",
      "be:\n",
      "  - 3rd_pers: is, 's, ai, Is, s\n",
      "  - base: are, be, being, Are, 'm, 're\n",
      "  - past: was, were, been, Was, where\n",
      "\n",
      "get:\n",
      "  - 3rd_pers: gets, Gets\n",
      "  - base: get, getting, Get, GET, got, Getting\n",
      "  - past: got, Got, gotten, GOT\n",
      "\n",
      "go:\n",
      "  - 3rd_pers: goes\n",
      "  - base: go, gon, going, Gon, Go, GO\n",
      "  - past: went, gone\n",
      "  - plural: go's\n",
      "  - singular: go\n",
      "\n",
      "do:\n",
      "  - 3rd_pers: does\n",
      "  - base: do, doing, Do, Doing, to\n",
      "  - past: done, did\n",
      "  - plural: Dos\n",
      "  - singular: do\n",
      "\n",
      "light:\n",
      "  - 3rd_pers: lights\n",
      "  - base: lighting, light\n",
      "  - comparative: lighter\n",
      "  - past: litten, lit, lighted\n",
      "  - plural: lights, LIGHTS\n",
      "  - positive: light\n",
      "  - singular: light, Light\n",
      "\n",
      "Sentence length statistics:\n",
      "Average sentence length (in words): 6.51\n",
      "Median sentence length: 5.0\n",
      "Range of sentence lengths: 1 to 40\n",
      "Average relative position of target words: 0.56\n"
     ]
    }
   ],
   "source": [
    "# Sentence context and morphological richness analysis\n",
    "print(\"\\n=== SENTENCE CONTEXT AND MORPHOLOGICAL RICHNESS ANALYSIS ===\")\n",
    "\n",
    "# Analyze word forms per lemma - morphological richness\n",
    "lemma_form_counts = df.groupby('Lemma')['Word Form'].nunique()\n",
    "print(f\"\\nAverage number of word forms per lemma: {lemma_form_counts.mean():.2f}\")\n",
    "print(f\"Median number of word forms per lemma: {lemma_form_counts.median()}\")\n",
    "print(f\"Maximum number of word forms per lemma: {lemma_form_counts.max()}\")\n",
    "\n",
    "# Find the lemmas with the most word forms (morphologically rich)\n",
    "rich_lemmas = lemma_form_counts.sort_values(ascending=False).head(10)\n",
    "print(\"\\nTop 10 lemmas by number of different word forms:\")\n",
    "print(rich_lemmas)\n",
    "\n",
    "# For each of these rich lemmas, show the different forms\n",
    "print(\"\\nExamples of rich inflection paradigms:\")\n",
    "for lemma in rich_lemmas.index[:5]:  # Show just top 5 to keep output manageable\n",
    "    forms = df[df['Lemma'] == lemma]['Word Form'].unique()\n",
    "    forms_by_inflection = df[df['Lemma'] == lemma].groupby('Inflection Label')['Word Form'].unique()\n",
    "    print(f\"\\n{lemma}:\")\n",
    "    for infl, word_forms in forms_by_inflection.items():\n",
    "        print(f\"  - {infl}: {', '.join(word_forms)}\")\n",
    "\n",
    "# Analyze sentence contexts\n",
    "# Calculate sentence lengths\n",
    "sentence_lengths = df.groupby('Sentence').size()\n",
    "print(f\"\\nSentence length statistics:\")\n",
    "print(f\"Average sentence length (in words): {sentence_lengths.mean():.2f}\")\n",
    "print(f\"Median sentence length: {sentence_lengths.median()}\")\n",
    "print(f\"Range of sentence lengths: {sentence_lengths.min()} to {sentence_lengths.max()}\")\n",
    "\n",
    "# Plot histogram of sentence lengths\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(sentence_lengths, bins=30)\n",
    "plt.xlabel('Number of Words')\n",
    "plt.ylabel('Count of Sentences')\n",
    "plt.title('Distribution of Sentence Lengths')\n",
    "plt.savefig('figures//sentence_length_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# Analyze distribution of target positions within sentences\n",
    "# Convert target index to relative position (0 to 1)\n",
    "max_indices = df.groupby('Sentence')['Target Index'].transform('max')\n",
    "df['relative_position'] = df['Target Index'] / np.maximum(max_indices, 1)  # Avoid division by zero\n",
    "\n",
    "# Plot distribution of relative positions\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(df['relative_position'], bins=20)\n",
    "plt.xlabel('Relative Position in Sentence (0=start, 1=end)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Target Word Positions within Sentences')\n",
    "plt.savefig('figures//target_position_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "print(f\"Average relative position of target words: {df['relative_position'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5fe82142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading gpt2 tokenizer for sentence stats…\n",
      "Loading pythia1.4b tokenizer for sentence stats…\n",
      "Loading gemma2b tokenizer for sentence stats…\n",
      "Loading qwen2 tokenizer for sentence stats…\n",
      "Loading bert-base-uncased tokenizer for sentence stats…\n",
      "Loading bert-large-uncased tokenizer for sentence stats…\n",
      "Loading deberta-v3-large tokenizer for sentence stats…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelli/Desktop/11424/lexeme-inflection-probing/venv/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sentences = df['Sentence'].drop_duplicates().tolist()\n",
    "\n",
    "avg_tokens_per_sentence = {}\n",
    "for model_name, config in MODEL_CONFIGS.items():\n",
    "    print(f\"Loading {model_name} tokenizer for sentence stats…\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config['tokenizer_name'])\n",
    "    # encode each sentence and count tokens\n",
    "    token_counts = [len(tokenizer.encode(s)) for s in sentences]\n",
    "    # store the mean (rounded to 1 decimal)\n",
    "    avg_tokens_per_sentence[model_name] = np.mean(token_counts).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb36837a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average subword tokens per sentence:\n",
      "       avg_tokens_per_sentence\n",
      "count                 7.000000\n",
      "mean                 22.628571\n",
      "std                   0.910521\n",
      "min                  21.600000\n",
      "25%                  21.800000\n",
      "50%                  22.700000\n",
      "75%                  23.400000\n",
      "max                  23.700000\n"
     ]
    }
   ],
   "source": [
    "# display as a DataFrame\n",
    "avg_sent_df = pd.DataFrame.from_dict(\n",
    "    avg_tokens_per_sentence, orient='index', columns=['avg_tokens_per_sentence']\n",
    ")\n",
    "print(\"\\nAverage subword tokens per sentence:\")\n",
    "print(avg_sent_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7f0a3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GENERATING LATEX TABLES ===\n",
      "\\begin{table}\n",
      "  \\centering\n",
      "  \\begin{tabular}{lr}\n",
      "    \\hline\n",
      "    \\textbf{} & \\textbf{Value} \\\\\n",
      "    \\hline\n",
      "    Total data points & 54816.0 \\\\\n",
      "    Unique sentences & 8415.0 \\\\\n",
      "    Unique lemmas & 7848.0 \\\\\n",
      "    Unique word forms & 11720.0 \\\\\n",
      "    Average tokens per sentence & 6.5 \\\\\n",
      "    \\hline\n",
      "  \\end{tabular}\n",
      "  \\caption{Dataset statistics for the GUM corpus}\n",
      "  \\label{tab:dataset}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}\n",
      "  \\centering\n",
      "  \\begin{tabular}{lrr}\n",
      "    \\hline\n",
      "    \\textbf{} & \\textbf{Count} & \\textbf{Percentage} \\\\\n",
      "    \\hline\n",
      "    Noun & 27111.0 & 49.5 \\\\\n",
      "    Verb & 17093.0 & 31.2 \\\\\n",
      "    Adjective & 10612.0 & 19.4 \\\\\n",
      "    \\hline\n",
      "  \\end{tabular}\n",
      "  \\caption{Distribution of word categories in the dataset}\n",
      "  \\label{tab:category_distribution}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}\n",
      "  \\centering\n",
      "  \\begin{tabular}{lrr}\n",
      "    \\hline\n",
      "    \\textbf{} & \\textbf{Count} & \\textbf{Percentage} \\\\\n",
      "    \\hline\n",
      "    singular & 19830.0 & 36.2 \\\\\n",
      "    base & 10076.0 & 18.4 \\\\\n",
      "    positive & 9926.0 & 18.1 \\\\\n",
      "    plural & 7281.0 & 13.3 \\\\\n",
      "    past & 5604.0 & 10.2 \\\\\n",
      "    3rd_pers & 1413.0 & 2.6 \\\\\n",
      "    comparative & 403.0 & 0.7 \\\\\n",
      "    superlative & 283.0 & 0.5 \\\\\n",
      "    \\hline\n",
      "  \\end{tabular}\n",
      "  \\caption{Distribution of inflection categories in the dataset}\n",
      "  \\label{tab:inflection_distribution}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}\n",
      "  \\centering\n",
      "  \\begin{tabular}{lrrrr}\n",
      "    \\hline\n",
      "    \\textbf{} & \\textbf{avg_tokens_per_word} & \\textbf{median_tokens_per_word} & \\textbf{max_tokens_per_word} & \\textbf{percent_multitoken} \\\\\n",
      "    \\hline\n",
      "    gpt2 & 0.09 & 0.0 & 3.0 & 0.9 \\\\\n",
      "    pythia1.4b & 0.09 & 0.0 & 3.0 & 0.9 \\\\\n",
      "    gemma2b & 0.19 & 0.0 & 3.0 & 1.9 \\\\\n",
      "    qwen2 & 0.07 & 0.0 & 2.0 & 0.65 \\\\\n",
      "    bert-base-uncased & 1.11 & 1.0 & 6.0 & 6.95 \\\\\n",
      "    bert-large-uncased & 1.11 & 1.0 & 6.0 & 6.95 \\\\\n",
      "    deberta-v3-large & 1.03 & 1.0 & 4.0 & 2.2 \\\\\n",
      "    \\hline\n",
      "  \\end{tabular}\n",
      "  \\caption{Tokenization statistics across different models}\n",
      "  \\label{tab:tokenization_stats}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}\n",
      "  \\centering\n",
      "  \\begin{tabular}{lr}\n",
      "    \\hline\n",
      "    \\textbf{} & \\textbf{Value} \\\\\n",
      "    \\hline\n",
      "    Average Words & 6.5 \\\\\n",
      "    Median Words & 5.0 \\\\\n",
      "    Minimum Words & 1.0 \\\\\n",
      "    Maximum Words & 40.0 \\\\\n",
      "    \\hline\n",
      "  \\end{tabular}\n",
      "  \\caption{Sentence length statistics}\n",
      "  \\label{tab:sentence_stats}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}\n",
      "  \\centering\n",
      "  \\begin{tabular}{lrr}\n",
      "    \\hline\n",
      "    \\textbf{} & \\textbf{Examples} & \\textbf{Percentage} \\\\\n",
      "    \\hline\n",
      "    Train & 43852 & 80.0% \\\\\n",
      "    Dev & 5482 & 10.0% \\\\\n",
      "    Test & 5482 & 10.0% \\\\\n",
      "    \\hline\n",
      "  \\end{tabular}\n",
      "  \\caption{Dataset splits}\n",
      "  \\label{tab:dataset_splits}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "# Generate LaTeX tables for the paper\n",
    "print(\"\\n=== GENERATING LATEX TABLES ===\")\n",
    "\n",
    "def dataframe_to_latex(df, caption, label):\n",
    "    \"\"\"Convert a DataFrame to a LaTeX table with proper formatting\"\"\"\n",
    "    if isinstance(df.index, pd.MultiIndex):\n",
    "        # Handle MultiIndex case\n",
    "        latex = \"\\\\begin{table}\\n  \\\\centering\\n\"\n",
    "        latex += \"  \\\\begin{tabular}{\" + \"l\" * (len(df.index.levels) + 1) + \"r\" * (len(df.columns)) + \"}\\n\"\n",
    "        latex += \"    \\\\hline\\n\"\n",
    "        \n",
    "        # Header\n",
    "        header = \"    \" + \" & \".join([\"\\\\textbf{\" + str(col) + \"}\" for col in [''] * len(df.index.levels) + list(df.columns)]) + \" \\\\\\\\\\n\"\n",
    "        latex += header\n",
    "        \n",
    "        latex += \"    \\\\hline\\n\"\n",
    "        \n",
    "        # Rows\n",
    "        current_level0 = None\n",
    "        for idx, row in df.iterrows():\n",
    "            if idx[0] != current_level0:\n",
    "                current_level0 = idx[0]\n",
    "                latex += \"    \\\\multicolumn{\" + str(len(df.index.levels) + len(df.columns)) + \"}{l}{\\\\textbf{\" + str(current_level0) + \"}} \\\\\\\\\\n\"\n",
    "            \n",
    "            values = [str(idx[-1])] + [str(round(val, 2) if isinstance(val, float) else val) for val in row.values]\n",
    "            latex += \"    \" + \" & \".join(values) + \" \\\\\\\\\\n\"\n",
    "        \n",
    "    else:\n",
    "        # Standard DataFrame\n",
    "        latex = \"\\\\begin{table}\\n  \\\\centering\\n\"\n",
    "        latex += \"  \\\\begin{tabular}{\" + \"l\" + \"r\" * (len(df.columns)) + \"}\\n\"\n",
    "        latex += \"    \\\\hline\\n\"\n",
    "        \n",
    "        # Header\n",
    "        header = \"    \\\\textbf{\" + \"} & \\\\textbf{\".join([str(col) for col in [''] + list(df.columns)]) + \"} \\\\\\\\\\n\"\n",
    "        latex += header\n",
    "        \n",
    "        latex += \"    \\\\hline\\n\"\n",
    "        \n",
    "        # Rows\n",
    "        for idx, row in df.iterrows():\n",
    "            values = [str(idx)] + [str(round(val, 2) if isinstance(val, float) else val) for val in row.values]\n",
    "            latex += \"    \" + \" & \".join(values) + \" \\\\\\\\\\n\"\n",
    "    \n",
    "    latex += \"    \\\\hline\\n\"\n",
    "    latex += \"  \\\\end{tabular}\\n\"\n",
    "    latex += f\"  \\\\caption{{{caption}}}\\n\"\n",
    "    latex += f\"  \\\\label{{{label}}}\\n\"\n",
    "    latex += \"\\\\end{table}\"\n",
    "    \n",
    "    return latex\n",
    "\n",
    "# Create main dataset statistics table\n",
    "stats_df = dataset_stats.set_index('Statistic')\n",
    "print(dataframe_to_latex(\n",
    "    stats_df, \n",
    "    \"Dataset statistics for the GUM corpus\", \n",
    "    \"tab:dataset\"\n",
    "))\n",
    "\n",
    "# Create category distribution table\n",
    "category_dist_df = pd.DataFrame({\n",
    "    'Count': category_counts,\n",
    "    'Percentage': category_percentages\n",
    "})\n",
    "print(\"\\n\" + dataframe_to_latex(\n",
    "    category_dist_df, \n",
    "    \"Distribution of word categories in the dataset\", \n",
    "    \"tab:category_distribution\"\n",
    "))\n",
    "\n",
    "# Create inflection distribution table\n",
    "inflection_df = pd.DataFrame({\n",
    "    'Count': inflection_counts,\n",
    "    'Percentage': inflection_percentages\n",
    "})\n",
    "print(\"\\n\" + dataframe_to_latex(\n",
    "    inflection_df, \n",
    "    \"Distribution of inflection categories in the dataset\", \n",
    "    \"tab:inflection_distribution\"\n",
    "))\n",
    "\n",
    "# Create tokenization statistics table\n",
    "print(\"\\n\" + dataframe_to_latex(\n",
    "    tokenizer_df.round(2), \n",
    "    \"Tokenization statistics across different models\", \n",
    "    \"tab:tokenization_stats\"\n",
    "))\n",
    "\n",
    "# Create sentence statistics table\n",
    "sentence_stats_df = pd.DataFrame({\n",
    "    'Statistic': ['Average Words', 'Median Words', 'Minimum Words', 'Maximum Words'],\n",
    "    'Value': [\n",
    "        round(sentence_lengths.mean(), 1),\n",
    "        int(sentence_lengths.median()),\n",
    "        int(sentence_lengths.min()),\n",
    "        int(sentence_lengths.max())\n",
    "    ]\n",
    "}).set_index('Statistic')\n",
    "print(\"\\n\" + dataframe_to_latex(\n",
    "    sentence_stats_df, \n",
    "    \"Sentence length statistics\", \n",
    "    \"tab:sentence_stats\"\n",
    "))\n",
    "\n",
    "# Create train/dev/test split table\n",
    "split_sizes_df = pd.DataFrame({\n",
    "    'Split': ['Train', 'Dev', 'Test'],\n",
    "    'Examples': [len(train_df), len(dev_df), len(test_df)],\n",
    "    'Percentage': [\n",
    "        f\"{len(train_df)/len(df):.1%}\",\n",
    "        f\"{len(dev_df)/len(df):.1%}\",\n",
    "        f\"{len(test_df)/len(df):.1%}\"\n",
    "    ]\n",
    "}).set_index('Split')\n",
    "print(\"\\n\" + dataframe_to_latex(\n",
    "    split_sizes_df, \n",
    "    \"Dataset splits\", \n",
    "    \"tab:dataset_splits\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa35cf50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
